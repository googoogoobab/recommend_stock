{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6503d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current search word:  $PLTR %23PLTR palantir 2020-11-01\n",
      "Scraping on headless mode.\n",
      "looking for tweets between 2020-11-01 and 2020-11-02 ...\n",
      " path : https://twitter.com/search?q=($PLTR%20OR%20%23PLTR%20OR%20palantir)%20until%3A2020-11-02%20since%3A2020-11-01%20%20-filter%3Areplies%20geocode%3A38.0000,-97.0000,2500km&src=typed_query\n",
      "scroll  1\n",
      "scroll  2\n",
      "scroll  3\n",
      "Empty DataFrame\n",
      "Columns: [UserScreenName, UserName, Timestamp, Text, Embedded_text, Emojis, Comments, Likes, Retweets, Image link, Tweet URL]\n",
      "Index: []\n",
      "Scraping on headless mode.\n",
      "looking for tweets between 2020-11-02 and 2020-11-03 ...\n",
      " path : https://twitter.com/search?q=($PLTR%20OR%20%23PLTR%20OR%20palantir)%20until%3A2020-11-03%20since%3A2020-11-02%20%20-filter%3Areplies%20geocode%3A38.0000,-97.0000,2500km&src=typed_query\n",
      "scroll  1\n",
      "scroll  2\n",
      "scroll  3\n",
      "Empty DataFrame\n",
      "Columns: [UserScreenName, UserName, Timestamp, Text, Embedded_text, Emojis, Comments, Likes, Retweets, Image link, Tweet URL]\n",
      "Index: []\n",
      "Scraping on headless mode.\n",
      "looking for tweets between 2020-11-03 and 2020-11-04 ...\n",
      " path : https://twitter.com/search?q=($PLTR%20OR%20%23PLTR%20OR%20palantir)%20until%3A2020-11-04%20since%3A2020-11-03%20%20-filter%3Areplies%20geocode%3A38.0000,-97.0000,2500km&src=typed_query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghkdwodnd321\\.conda\\envs\\recommend_stock_37\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:393: UserWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  warnings.warn(\"find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\")\n",
      "C:\\Users\\ghkdwodnd321\\.conda\\envs\\recommend_stock_37\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:426: UserWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  warnings.warn(\"find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet made at: 2020-11-03T22:59:07.000Z is found.\n",
      "scroll  1\n",
      "scroll  2\n",
      "scroll  3\n",
      "        UserScreenName        UserName                 Timestamp  \\\n",
      "0  Satish Gattadahalli  @SGattadahalli  2020-11-03T22:59:07.000Z   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Satish Gattadahalli\\n@SGattadahalli\\n·\\n2020년 ...   \n",
      "\n",
      "                                       Embedded_text Emojis Comments Likes  \\\n",
      "0  Palantir is in talks with the U.K. government ...                         \n",
      "\n",
      "  Retweets Image link                                          Tweet URL  \n",
      "0                  []  https://twitter.com/SGattadahalli/status/13237...  \n",
      "Scraping on headless mode.\n",
      "looking for tweets between 2020-11-04 and 2020-11-05 ...\n",
      " path : https://twitter.com/search?q=($PLTR%20OR%20%23PLTR%20OR%20palantir)%20until%3A2020-11-05%20since%3A2020-11-04%20%20-filter%3Areplies%20geocode%3A38.0000,-97.0000,2500km&src=typed_query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghkdwodnd321\\.conda\\envs\\recommend_stock_37\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:393: UserWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  warnings.warn(\"find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\")\n",
      "C:\\Users\\ghkdwodnd321\\.conda\\envs\\recommend_stock_37\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:426: UserWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  warnings.warn(\"find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet made at: 2020-11-04T13:30:17.000Z is found.\n",
      "scroll  1\n",
      "scroll  2\n",
      "scroll  3\n",
      "   UserScreenName      UserName                 Timestamp  \\\n",
      "0  #MasterFlipper  @MoneyMirCEO  2020-11-04T13:30:17.000Z   \n",
      "\n",
      "                                            Text Embedded_text Emojis  \\\n",
      "0  #MasterFlipper\\n@MoneyMirCEO\\n·\\n2020년 11월 4일    $GME $PLTR          \n",
      "\n",
      "  Comments Likes Retweets Image link  \\\n",
      "0                                 []   \n",
      "\n",
      "                                           Tweet URL  \n",
      "0  https://twitter.com/MoneyMirCEO/status/1323980...  \n",
      "Scraping on headless mode.\n",
      "looking for tweets between 2020-11-05 and 2020-11-06 ...\n",
      " path : https://twitter.com/search?q=($PLTR%20OR%20%23PLTR%20OR%20palantir)%20until%3A2020-11-06%20since%3A2020-11-05%20%20-filter%3Areplies%20geocode%3A38.0000,-97.0000,2500km&src=typed_query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghkdwodnd321\\.conda\\envs\\recommend_stock_37\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:393: UserWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  warnings.warn(\"find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\")\n",
      "C:\\Users\\ghkdwodnd321\\.conda\\envs\\recommend_stock_37\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:426: UserWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  warnings.warn(\"find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet made at: 2020-11-05T15:29:52.000Z is found.\n",
      "Tweet made at: 2020-11-05T23:03:48.000Z is found.\n",
      "scroll  1\n",
      "Tweet made at: 2020-11-05T15:39:41.000Z is found.\n",
      "Tweet made at: 2020-11-05T20:57:35.000Z is found.\n",
      "scroll  2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36940\\2882130667.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m                        \u001b[0mfrom_account\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m               \u001b[0mheadless\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Top\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m               resume=False, filter_replies=True, proximity=False,geocode=\"38.0000,-97.0000,2500km\")\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\recommend_stock_37\\lib\\site-packages\\Scweet\\scweet.py\u001b[0m in \u001b[0;36mscrape\u001b[1;34m(since, until, words, to_account, from_account, mention_account, interval, lang, headless, limit, display_type, resume, proxy, hashtag, show_images, save_images, save_dir, filter_replies, proximity, geocode, minreplies, minlikes, minretweets)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;31m# start scrolling and get tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscrolling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_parsed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscroll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_position\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m                 \u001b[0mkeep_scroling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscrolling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_parsed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscroll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;31m# keep updating <start date> and <end date> for every search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\recommend_stock_37\\lib\\site-packages\\Scweet\\utils.py\u001b[0m in \u001b[0;36mkeep_scroling\u001b[1;34m(driver, data, writer, tweet_ids, scrolling, tweet_parsed, limit, scroll, last_position, save_images)\u001b[0m\n\u001b[0;32m    301\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m                     \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# attempt another scroll\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mlast_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurr_position\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######## Twitter Data Stream######################################\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "#Define variables below\n",
    "path=\"data/\" #folder where the data will be saved\n",
    "start_date=\"2020-11-01\" #first day for extracting tweets\n",
    "last_date=\"2022-05-02\" #last day (included) for extracting tweets\n",
    "\n",
    "search_word=[\n",
    "[\"PLTR\",\"palantir\",\"2020-11-01\"],\n",
    "[\"TSLA\",\"Tesla\",\"2010-07-02\"],\n",
    "[\"CPNG\", \"Coupang\", \"2021-03-12\"],\n",
    "[\"RBLX\", \"Roblox\", \"2021-03-12\"],\n",
    "[\"RIVN\", \"Rivian\", \"2021-11-12\"],\n",
    "[\"GME\", \"GameStop\", \"2010-05-01\"],\n",
    "[\"NKLA\", \"Nikola\", \"2018-06-13\"],\n",
    "[\"ROKU\", \"ROKU\", \"2017-09-29\"],\n",
    "[\"TDOC\",\"Teladoc\", \"2015-07-02\"]\n",
    "             ]\n",
    "\n",
    "\n",
    "from Scweet.scweet import scrape\n",
    "from Scweet.user import get_user_information, get_users_following, get_users_followers\n",
    "\n",
    "\n",
    "######## Get Tweets######################################\n",
    "\n",
    "#search for each word in search list separately\n",
    "for stock_code,stock_name,start_date in search_word:\n",
    "    print(\"Current search word: \",\"$\"+stock_code,\"%23\"+stock_code,stock_name,start_date)\n",
    "\n",
    "    #search for each date separately\n",
    "    for date_since in pd.date_range(start=start_date,end=last_date):\n",
    "\n",
    "        tweets = scrape(words=[\"$\"+stock_code,\"%23\"+stock_code,stock_name], since=date_since.strftime('%Y-%m-%d'), until=(date_since+dt.timedelta(days=1)).strftime('%Y-%m-%d'),\n",
    "                       from_account = None, interval=1, \n",
    "              headless=True, display_type=\"Top\", save_images=False, \n",
    "              resume=False, filter_replies=True, proximity=False,geocode=\"38.0000,-97.0000,2500km\")\n",
    "        \n",
    "        #put content of object into list\n",
    "        tweets=tweets[[\"UserScreenName\",\"Embedded_text\",\"Timestamp\",\"Comments\", \"Likes\", \"Retweets\",]]\n",
    "        tweets.columns = ['user',\"text\",\"date\",\"comments\",\"likes\",\"retweets\"]\n",
    "        tweets.insert(0,\"search_word\",stock_name)\n",
    "\n",
    "\n",
    "        #save daily results\n",
    "        df=tweets\n",
    "        df.to_csv(path+stock_name+\"_\"+date_since.strftime('%Y-%m-%d')+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e97640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
